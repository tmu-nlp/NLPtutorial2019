{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "a\n",
      "0 2\n",
      "ab\n",
      "1 2\n",
      "b\n",
      "0 3\n",
      "abc\n",
      "1 3\n",
      "bc\n",
      "2 3\n",
      "c\n",
      "ab\tc\n",
      "0 1\n",
      "b\n",
      "0 2\n",
      "bb\n",
      "1 2\n",
      "b\n",
      "0 3\n",
      "bbc\n",
      "1 3\n",
      "bc\n",
      "2 3\n",
      "c\n",
      "b\tbc\n"
     ]
    }
   ],
   "source": [
    "# divide-word.py\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# データパス\n",
    "model_path = \"../../test/04-model.txt\"\n",
    "input_path = \"../../test/04-input.txt\"\n",
    "\n",
    "uni_probs = defaultdict(lambda: 0)\n",
    "# unigramのモデルを読み込み\n",
    "with open(model_path) as f:\n",
    "    for line in f:\n",
    "        unigram, prob = line.split()\n",
    "        uni_probs[unigram] = float(prob)\n",
    "\n",
    "with open(input_path) as f:\n",
    "    # 前向きステップ\n",
    "    for line in f:\n",
    "        \n",
    "        best_edge = [None] * len(line)\n",
    "        best_score = [0] * len(line)\n",
    "        for word_end in range(1, len(line)):\n",
    "            best_score[word_end] = 1e10\n",
    "            for word_begin in range(word_end):\n",
    "                print(word_begin, word_end)\n",
    "                word = line[word_begin : word_end]\n",
    "                print(word)\n",
    "                if word in uni_probs.keys() or len(word) == 1:\n",
    "                    prob = uni_probs[word]\n",
    "                    my_score = best_score[word_begin] - math.log(prob, 2)\n",
    "                    if my_score < best_score[word_end]:\n",
    "                        best_score[word_end] = my_score\n",
    "                        best_edge[word_end] = (word_begin, word_end)\n",
    "        '''\n",
    "        ex.\n",
    "        best_score = [0, 5.770780162668462, 11.541560325336924, 8.80043975151574]\n",
    "        best_edge = [None, (0, 1), (1, 2), (1, 3)]\n",
    "        '''\n",
    "        words = []\n",
    "        next_edge = best_edge[len(best_edge) - 1]\n",
    "        while next_edge:\n",
    "            # このエッジの部分文字列を追加\n",
    "            word = line[next_edge[0]:next_edge[1]]\n",
    "            words.append(word)\n",
    "            next_edge = best_edge[next_edge[0]]\n",
    "        words = words[::-1]\n",
    "        print(\"\\t\".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n$ ../../script/gradews.pl ../../data/wiki-ja-test.word tutorial03.txt\\nSent Accuracy: 23.81% (20/84)\\nWord Prec: 71.88% (1943/2703)\\nWord Rec: 84.22% (1943/2307)\\nF-meas: 77.56%\\nBound Accuracy: 86.30% (2784/3226)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide-word.py\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "UNKNOWN_RATE = 0.05\n",
    "N = 1000000\n",
    "\n",
    "word_data_path = \"../../data/wiki-ja-train.word\"\n",
    "save_model_path = \"wiki-ja-train-model.txt\"\n",
    "input_path = \"../../data/wiki-ja-test.txt\"\n",
    "output_path = \"tutorial03.txt\"\n",
    "# ディクショナリの初期値を0に設定\n",
    "d = defaultdict(lambda: 0)\n",
    "total_count = 0\n",
    "\n",
    "# テキストの読み込み\n",
    "with open(word_data_path) as f:\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        words.append(\"</s>\")\n",
    "        # 特定の単語の出現数と全体の単語数をカウント\n",
    "        for word in words:\n",
    "            d[word] += 1\n",
    "            total_count += 1\n",
    "\n",
    "# 単語と出現率を出力\n",
    "with open(save_model_path, mode='w') as f:\n",
    "    for key, value in d.items():\n",
    "        prob = value / total_count\n",
    "        f.write(\"{} {}\\n\".format(key, prob))\n",
    "\n",
    "\n",
    "uni_probs = defaultdict(lambda: 0)\n",
    "# unigramのモデルを読み込み\n",
    "with open(save_model_path) as f:\n",
    "    for line in f:\n",
    "        unigram, prob = line.split()\n",
    "        uni_probs[unigram] = float(prob)\n",
    "\n",
    "with open(input_path) as f, open(output_path, mode=\"w\") as fw:\n",
    "    # 前向きステップ\n",
    "    for sentence in f:\n",
    "        # edgeとscoreの初期化\n",
    "        best_edge = [None] * len(sentence)\n",
    "        best_score = [0] * len(sentence)\n",
    "        # 1, 2, 3,..., N文字目までの最適な経路を求めていく\n",
    "        for word_end in range(1, len(sentence)):\n",
    "            # n文字目までのスコアを大きく取っておき、小さい時に更新する\n",
    "            best_score[word_end] = 1e10\n",
    "            # 開始エッジ(word_begin)\n",
    "            for word_begin in range(word_end):\n",
    "                # 文の開始位置と終端位置から候補の文字を出す\n",
    "                word = sentence[word_begin : word_end]\n",
    "                # wordは、 A, AB, B, ABC, BC, Cのように更新されていく\n",
    "                # wordがユニグラムモデルに入っていない場合か、単語が一文字の時は飛ばす\n",
    "                if not(word in uni_probs.keys() or len(word) == 1):\n",
    "                    continue\n",
    "                # その単語が出る確率を計算(unknown対策もする)\n",
    "                prob = (1 - UNKNOWN_RATE) * uni_probs[word] + (UNKNOWN_RATE / N)\n",
    "                # 開始単語に着くまでのスコアと今回の単語のスコアを足す\n",
    "                # -logなので、確率が低い程スコアが大きくなり、確率が高い程スコアは変化しない\n",
    "                my_score = best_score[word_begin] - math.log(prob, 2)\n",
    "                # スコアが改善された場合、代入する\n",
    "                if my_score < best_score[word_end]:\n",
    "                    best_score[word_end] = my_score\n",
    "                    best_edge[word_end] = (word_begin, word_end)\n",
    "        '''\n",
    "        ex.\n",
    "        best_score = [0, 5.770780162668462, 11.541560325336924, 8.80043975151574]\n",
    "        best_edge = [None, (0, 1), (1, 2), (1, 3)]\n",
    "        '''\n",
    "        # 前からそのエッジに着くまでの最適経路を出しているので、逆から辿れば終端までの最適経路がわかる\n",
    "        # 初期化\n",
    "        words = []\n",
    "        next_edge = best_edge[len(best_edge) - 1]\n",
    "        # 最後のエッジ(0)にはNoneが入っているので、Noneが来るまで\n",
    "        while next_edge:\n",
    "            # このエッジの部分文字列を追加\n",
    "            word = sentence[next_edge[0]:next_edge[1]]\n",
    "            words.append(word)\n",
    "            next_edge = best_edge[next_edge[0]]\n",
    "        # 終端から辿っているので逆順に直す\n",
    "        words = words[::-1]\n",
    "        # 単語分割をスペース区切りで出力\n",
    "        out_put_str = \" \".join(words)\n",
    "        fw.write(out_put_str + \"\\n\")\n",
    "\n",
    "'''\n",
    "$ ../../script/gradews.pl ../../data/wiki-ja-test.word tutorial03.txt\n",
    "Sent Accuracy: 23.81% (20/84)\n",
    "Word Prec: 71.88% (1943/2703)\n",
    "Word Rec: 84.22% (1943/2307)\n",
    "F-meas: 77.56%\n",
    "Bound Accuracy: 86.30% (2784/3226)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent Accuracy: 23.81% (20/84)\n",
      "Word Prec: 71.88% (1943/2703)\n",
      "Word Rec: 84.22% (1943/2307)\n",
      "F-meas: 77.56%\n",
      "Bound Accuracy: 86.30% (2784/3226)\n"
     ]
    }
   ],
   "source": [
    "!../../script/gradews.pl ../../data/wiki-ja-test.word tutorial03.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\t0.0907179533\n",
      "b\t0.0183156389\n",
      "c\t0.100258844\n",
      "ab\t0.246596964\n",
      "bc\t0.122456428\n"
     ]
    }
   ],
   "source": [
    "!cat  ../../test/04-model.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab c\n",
      "b bc\n"
     ]
    }
   ],
   "source": [
    "!cat ../../test/04-answer.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "校正（こうせい、英：ｐｒｏｏｆｒｅａｄｉｎｇ、中：校対）は、印刷物等の字句や内容、体裁、色彩の誤りや不具合を、あらかじめ修正すること。\n",
      "校合（きょうごう）ともいう。\n",
      "出版にあたっては、印刷に先立って仮刷りを行い、それと原稿の内容を突き合わせ、誤植や体裁上の不備を正す。\n",
      "文字や数字ばかりでなく、デザインや発色の確認も行い、特に発色の確認を行う校正を色校正（色校）という。\n",
      "かつて「校正」の語は古典作品の写本（原文が存在している場合は原文）と別の写本（異本）を照合する「校訂」の意味でも使われた。\n"
     ]
    }
   ],
   "source": [
    "!cat ../../data/wiki-ja-test.txt | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然 言語 処理 （ しぜん げんご しょり 、 英語 ： 　 ｎａｔｕｒａｌ 　 ｌａｎｇｕａｇｅ 　 ｐｒｏｃｅｓｓｉｎｇ 、 略称 ： ＮＬＰ ） は 、 人間 が 日常 的 に 使 っ て い る 自然 言語 を コンピュータ に 処理 さ せ る 一連 の 技術 で あ り 、 人工 知能 と 言語 学 の 一 分野 で あ る 。\n",
      "「 計算 言語 学 」 （ ｃｏｍｐｕｔａｔｉｏｎａｌ 　 ｌｉｎｇｕｉｓｔｉｃｓ ） も 同じ 意味 で あ る が 、 前者 は 工学 的 な 視点 から の 言語 処理 を さ す の に 対 し て 、 後者 は 言語 学 的 視点 を 重視 する 手法 を さ す 事 が 多 い 。\n",
      "データベース 内 の 情報 を 自然 言語 に 変換 し たり 、 自然 言語 の 文章 を より 形式 的 な （ コンピュータ が 理解 し やす い ） 表現 に 変換 する と い っ た 処理 が 含 ま れ る 。\n",
      "自然 言語 の 理解 を コンピュータ に さ せ る こと は 、 自然 言語 理解 と さ れ て い る 。\n",
      "自然 言語 理解 と 、 自然 言語 処理 の 差 は 、 意味 を 扱 う か 、 扱 わ な い か と い う 説 も あ っ た が 、 最近 は 数理 的 な 言語 解析 手法 （ 統計 や 確率 など ） が 広め られ た 為 、 パーサ （ 統語 解析 器 ） など が 一段 と 精度 や 速度 が 上が り 、 その 意味 合い は 違 っ て き て い る 。\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat ../../data/wiki-ja-train.word | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "校正 （ こうせい 、 英 ： ｐｒｏｏｆ ｒｅａｄｉｎｇ 、 中 ： 校 対 ） は 、 印刷 物 等 の 字句 や 内容 、 体裁 、 色彩 の 誤り や 不 具合 を 、 あらかじめ 修正 する こと 。\n",
      "校合 （ きょうごう ） と も い う 。\n",
      "出版 に あた っ て は 、 印刷 に 先立 っ て 仮 刷り を 行 い 、 それ と 原稿 の 内容 を 突き合わせ 、 誤植 や 体裁 上 の 不備 を 正 す 。\n",
      "文字 や 数字 ばかり で な く 、 デザイン や 発色 の 確認 も 行 い 、 特に 発色 の 確認 を 行 う 校正 を 色 校 正 （ 色校 ） と い う 。\n",
      "かつて 「 校正 」 の 語 は 古典 作品 の 写本 （ 原文 が 存在 し て い る 場合 は 原文 ） と 別 の 写本 （ 異本 ） を 照合 する 「 校訂 」 の 意味 で も 使 わ れ た 。\n"
     ]
    }
   ],
   "source": [
    "!cat ../../data/wiki-ja-test.word | head -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
