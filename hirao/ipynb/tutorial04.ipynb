{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-hmm.py\n",
    "from collections import defaultdict\n",
    "\n",
    "# train_input_path = \"../../test/05-train-input.txt\"\n",
    "train_input_path = \"../../data/wiki-en-train.norm_pos\"\n",
    "model_path = \"tutorial04.txt\"\n",
    "\n",
    "# モデル読み込み\n",
    "transition = defaultdict(lambda: 0)\n",
    "emission = defaultdict(lambda: 0)\n",
    "possible_tags = defaultdict(lambda: 0)\n",
    "\n",
    "with open(train_input_path) as f, open(model_path, mode=\"w\") as fw:\n",
    "    for line in f:\n",
    "        word_tags = line.split()\n",
    "        previous = \"<s>\"\n",
    "        possible_tags[previous] += 1\n",
    "        for word, tag in [x.split(\"_\") for x in word_tags]:\n",
    "            transition[f\"{previous} {tag}\"] += 1\n",
    "            possible_tags[tag] += 1\n",
    "            emission[f\"{tag} {word}\"] += 1\n",
    "            previous = tag\n",
    "        transition[f\"{previous} </s>\"] += 1\n",
    "    for key, value in transition.items():\n",
    "        previous, word = key.split()\n",
    "        output = f\"T {key} {value/possible_tags[previous]}\"\n",
    "        fw.write(output + \"\\n\")\n",
    "    for key, value in emission.items():\n",
    "        previous, word = key.split()\n",
    "        output = f\"E {key} {value/possible_tags[previous]}\"\n",
    "        fw.write(output + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-hmm.py\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "input_model_path = \"tutorial04.txt\"\n",
    "# test_input_path = \"../../test/05-test-input.txt\"\n",
    "test_input_path = \"../../data/wiki-en-test.norm\"\n",
    "output_path = \"my_answer.pos\"\n",
    "UNKNOWN_RATE = 0.05\n",
    "N = 1e6\n",
    "\n",
    "transition = defaultdict(lambda: 0)\n",
    "emission = defaultdict(lambda: 0)\n",
    "possible_tags = defaultdict(lambda: 0)\n",
    "\n",
    "with open(input_model_path) as fr:\n",
    "    for line in fr:\n",
    "        typ, context, word, prob = line.split()\n",
    "        possible_tags[context] = 1\n",
    "        if typ == \"T\":\n",
    "            transition[f\"{context} {word}\"] = float(prob)\n",
    "        else:\n",
    "            emission[f\"{context} {word}\"] = float(prob)\n",
    "\n",
    "with open(test_input_path) as f, open(output_path, mode=\"w\") as fw:\n",
    "    for line in f:\n",
    "        words = line.split()\n",
    "        l = len(words)\n",
    "\n",
    "        best_score = defaultdict(lambda: 0)\n",
    "        best_edge = defaultdict(lambda: 0)\n",
    "\n",
    "        best_score[\"0 <s>\"] = 0\n",
    "        best_edge[\"0 <s>\"] = None\n",
    "\n",
    "        for i in range(l):\n",
    "            for prev_tag in possible_tags.keys():\n",
    "                for next_tag in possible_tags.keys():\n",
    "                    if f\"{i} {prev_tag}\" not in best_score or f\"{prev_tag} {next_tag}\" not in transition:\n",
    "                        continue\n",
    "                    pt = transition[f\"{prev_tag} {next_tag}\"]\n",
    "                    pe = (1 - UNKNOWN_RATE) * emission[f\"{next_tag} {words[i]}\"] + UNKNOWN_RATE / N\n",
    "                    \n",
    "                    score = best_score[f\"{i} {prev_tag}\"] - math.log(pt, 2) - math.log(pe, 2)\n",
    "                    if f\"{i+1} {next_tag}\" not in best_score or best_score[f\"{i+1} {next_tag}\"] > score:\n",
    "                        best_score[f\"{i+1} {next_tag}\"] = score\n",
    "                        best_edge[f\"{i+1} {next_tag}\"] = f\"{i} {prev_tag}\"\n",
    "        for tag in possible_tags.keys():\n",
    "            if f\"{l} {tag}\" in best_score and f\"{tag} </s>\" in transition:\n",
    "                pt = transition[f\"{tag} </s>\"]\n",
    "                pe = (1 - UNKNOWN_RATE) * emission[f\"{tag} </s>\"] + UNKNOWN_RATE / N\n",
    "                score = best_score[f\"{l} {tag}\"] - math.log(pt, 2) - math.log(pe, 2)\n",
    "                if f\"{l+1} </s>\" not in best_score or best_score[f\"{l+1} </s>\"] > score:\n",
    "                    best_score[f\"{l+1} </s>\"] = score\n",
    "                    best_edge[f\"{l+1} </s>\"] = f\"{l} {tag}\"\n",
    "        tags = []\n",
    "        next_edge = best_edge[f\"{l+1} </s>\"]\n",
    "        while next_edge != \"0 <s>\" and next_edge != None:\n",
    "            position, tag = next_edge.split()\n",
    "            tags.append(tag)\n",
    "            next_edge = best_edge[next_edge]\n",
    "        tags = tags[::-1]\n",
    "        fw.write(\" \".join(tags) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T <s> X 1.0\n",
      "T X Y 0.6666666666666666\n",
      "T Y Z 0.5\n",
      "T Z </s> 1.0\n",
      "T X X 0.3333333333333333\n",
      "T Y </s> 0.5\n",
      "E X a 0.6666666666666666\n",
      "E Y b 1.0\n",
      "E Z a 1.0\n",
      "E X c 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "!cat tutorial04.txt | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_X b_Y a_Z\n",
      "a_X c_X b_Y\n"
     ]
    }
   ],
   "source": [
    "!cat ../../test/05-train-input.txt | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b a\n",
      "a c b\n"
     ]
    }
   ],
   "source": [
    "!cat ../../test/05-test-input.txt | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T <s> X 1.000000\n",
      "T X X 0.333333\n",
      "T X Y 0.666667\n",
      "T Y </s> 0.500000\n",
      "T Y Z 0.500000\n",
      "T Z </s> 1.000000\n",
      "E X a 0.666667\n",
      "E X c 0.333333\n",
      "E Y b 1.000000\n",
      "E Z a 1.000000\n"
     ]
    }
   ],
   "source": [
    "!cat ../../test/05-train-answer.txt | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Y Z\n",
      "X X Y\n"
     ]
    }
   ],
   "source": [
    "!cat ../../test/05-test-answer.txt | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN JJ NNS , DT NN -LRB- NN -RRB- VBZ DT JJ NN IN JJ NN NN , WDT VBZ DT NN IN VBG DT NN IN DT NN -LRB- FW NN -RRB- VBZ VBN IN DT NN , WRB DT NN VBZ JJ NNS -LRB- NN -RRB- .\n",
      "DT NN TO DT NN IN JJ NN NN , JJ IN NN , VBG NN IN NN NNS , NN NN , NN , NN FW NN .\n",
      "NNP VBZ RB RB TO DT NN WRB JJ NNS VB RB JJ NNS IN NN IN DT NN IN NN NNS CC NNS .\n",
      "DT JJ NN IN NNS VBP VBN VBN , IN JJ NNS WDT VBP DT NN NN IN JJ NNS , TO JJ NN NN NNS IN WDT DT NN VBZ VBN IN DT JJ NN IN DT NN IN RB JJ NNS , TO RB JJ NNS IN NN NN IN NNS , RB JJ NN NNS .\n",
      "IN DT , JJ NN NNS VBP VBN DT RBS JJ NNS TO NN .\n",
      "JJ NN VBZ JJ TO NN IN DT NN IN NN .\n",
      "IN NNP , NN IN DT JJ -LRB- NN -RRB- NN VBZ VBN IN CD NN , IN DT NNS IN JJ NNS VBG IN DT NN .\n",
      "IN DT NN NNS , JJ NNS IN DT NN TO DT NN VBP VBN VBN IN JJ NN NNS -LRB- FW , NN -RRB- , WRB DT JJ NN IN DT JJS JJ NN IN RB IN DT RBS JJ NN VBD DT NN CC JJ NN , RB .\n",
      "DT NN VBZ CD -RRB- : `` JJ NN '' CC `` DT NNS '' NN .\n",
      "DT NN VBZ IN DT NN IN DT JJ NN IN NN NNS WDT VBD RB VBN , IN IN DT JJ DT DT NNS IN DT NN IN VBG NN VBP TO VB NNS .\n"
     ]
    }
   ],
   "source": [
    "!cat my_answer.pos | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN JJ NNS , JJ NN -LRB- NN -RRB- VBZ DT JJ NN IN JJ NN NN , WDT VBZ DT NN IN VBG WDT NN IN DT NN -LRB- FW NN -RRB- VBZ VBN IN DT NN , WRB DT NN VBZ JJ NNS -LRB- NN -RRB- .\n",
      "DT NN TO DT NN VBZ JJ JJ NN , JJ IN NN , VBG NN IN NN NNS , NN NN , NN , NN FW FW .\n",
      "NNP VBZ VBN RB TO DT NN WRB NNP NNS VBP RB JJ NNS IN NN IN DT NN IN NN NNS CC NNS .\n",
      "DT JJ NN IN NNS VBP VBN VBN , IN JJ NNS WDT VBP DT NN VBN IN JJ NNS , TO JJ NN NN NNS IN WDT DT NN VBZ VBN IN DT JJ NN IN DT NN IN RB JJ NNS , TO RB JJ NNS WDT VBP NNS IN NNS , RB VBG NN NNS .\n",
      "IN DT , JJ NN NNS VBP VBN DT RBS JJ NNS TO NN .\n",
      "JJ NN VBZ JJ TO NN IN DT NN IN NNS .\n",
      "IN NNP , NN IN DT JJ -LRB- JJ -RRB- NN VBZ RB IN CD NN , IN DT NNS IN JJ NNS VBG IN CD NN .\n",
      "IN JJ NN NNS , JJ NNS IN CD NN TO CD NN VBP VBN VBN IN JJ NN NNS -LRB- NN , NN -RRB- , WRB DT NN NN IN DT JJS JJ NN IN RB VBG DT RBS JJ NN VBD CD NN CC CD NN , RB .\n",
      "NN NN VBZ CD NNS : `` JJ NN '' CC `` DT NNS '' NN .\n",
      "DT JJ VBZ VBG DT NNS IN DT JJ NN IN NN NNS WDT VBD RB VBN , IN IN DT JJ PDT DT NNS IN DT NN IN VBG NN VBP TO VB VBN .\n"
     ]
    }
   ],
   "source": [
    "!cat ../../data/wiki-en-test.pos | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In computational linguistics , word-sense disambiguation -LRB- WSD -RRB- is an open problem of natural language processing , which governs the process of identifying which sense of a word -LRB- i.e. meaning -RRB- is used in a sentence , when the word has multiple meanings -LRB- polysemy -RRB- .\n",
      "The solution to this problem impacts other computer-related writing , such as discourse , improving relevance of search engines , anaphora resolution , coherence , inference et cetera .\n",
      "Research has progressed steadily to the point where WSD systems achieve sufficiently high levels of accuracy on a variety of word types and ambiguities .\n",
      "A rich variety of techniques have been researched , from dictionary-based methods that use the knowledge encoded in lexical resources , to supervised machine learning methods in which a classifier is trained for each distinct word on a corpus of manually sense-annotated examples , to completely unsupervised methods that cluster occurrences of words , thereby inducing word senses .\n",
      "Among these , supervised learning approaches have been the most successful algorithms to date .\n",
      "Current accuracy is difficult to state without a host of caveats .\n",
      "In English , accuracy at the coarse-grained -LRB- homograph -RRB- level is routinely above 90 % , with some methods on particular homographs achieving over 96 % .\n",
      "On finer-grained sense distinctions , top accuracies from 59.1 % to 69.0 % have been reported in recent evaluation exercises -LRB- SemEval-2007 , Senseval-2 -RRB- , where the baseline accuracy of the simplest possible algorithm of always choosing the most frequent sense was 51.4 % and 57 % , respectively .\n",
      "WSD task has two variants : `` lexical sample '' and `` all words '' task .\n",
      "The former comprises disambiguating the occurrences of a small sample of target words which were previously selected , while in the latter all the words in a piece of running text need to be disambiguated .\n",
      "cat: stdout: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "!cat ../../data/wiki-en-test.norm | head -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.82% (4144/4563)\n",
      "\n",
      "Most common mistakes:\n",
      "NNS --> NN\t45\n",
      "NN --> JJ\t27\n",
      "NNP --> NN\t22\n",
      "JJ --> DT\t22\n",
      "JJ --> NN\t12\n",
      "VBN --> NN\t12\n",
      "NN --> IN\t11\n",
      "NN --> DT\t10\n",
      "NNP --> JJ\t8\n",
      "JJ --> VBN\t7\n"
     ]
    }
   ],
   "source": [
    "!../../script/gradepos.pl ../../data/wiki-en-test.pos my_answer.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
